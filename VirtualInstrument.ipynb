{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio, struct\n",
    "import multiprocessing\n",
    "import threading\n",
    "import numpy as np\n",
    "import _thread\n",
    "import time\n",
    "from scipy import signal\n",
    "import cv2\n",
    "import math\n",
    "from math import sin, cos, pi\n",
    "import imutils\n",
    "import os\n",
    "import wave\n",
    "from os.path import realpath, normpath\n",
    "\n",
    "import binascii\n",
    "import struct\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import scipy.cluster\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Global Variable Shared by Image Process and Audio Generation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KS = [0] * 12\n",
    "CONTINUE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Utility Function</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask == 1,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Face Recognition With Haar Feature-Based Cascade Classifiers</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDetectedFace(frame):\n",
    "    \"\"\"\n",
    "    frame    : the input frame in BGR color space\n",
    "    \"\"\"\n",
    "    NUM_CLUSTERS = 5\n",
    "    FaceDetected = False\n",
    "    peakHSV = None\n",
    "    # get xml path \n",
    "    s = realpath(cv2.__file__).split(\"\\\\\")[:-1]\n",
    "    xmlPath = os.path.join(os.path.join(*s), \"data\")\n",
    "    # Load the cascade classifier\n",
    "    face_cascade = cv2.CascadeClassifier(os.path.join(xmlPath, 'haarcascade_frontalface_default.xml'))\n",
    "    eye_cascade = cv2.CascadeClassifier(os.path.join(xmlPath, 'haarcascade_eye.xml'))\n",
    "    # Convert the frame from default BGR to Gray color space\n",
    "    frameGray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Use Histogram Equalization to enhance the contrast\n",
    "    frameGray = cv2.equalizeHist(frameGray)\n",
    "\n",
    "    # detect face in current frame\n",
    "    faces = face_cascade.detectMultiScale(frameGray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = frameGray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    \n",
    "    if len(faces) > 0:\n",
    "        print(\"face detected\")\n",
    "        FaceDetected = True\n",
    "        image = frame[y:y+h, x:x+w]\n",
    "        shape = image.shape\n",
    "        ar = image.reshape(scipy.product(shape[:2]), shape[2]).astype(float)\n",
    "        codes, dist = scipy.cluster.vq.kmeans(ar, NUM_CLUSTERS)\n",
    "        vecs, dist = scipy.cluster.vq.vq(ar, codes)         # assign codes\n",
    "        counts, bins = scipy.histogram(vecs, len(codes))    # count occurrences\n",
    "        index_max = scipy.argmax(counts)                    # find most frequent\n",
    "        peak = codes[index_max]\n",
    "        peak = peak.reshape(1,1,3)\n",
    "        peak = peak.astype(\"uint8\")\n",
    "        peakHSV = cv2.cvtColor(peak, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    return FaceDetected, frame, peakHSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Skin Detection using HSV boundary</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSkinMask(frame, lower, upper):\n",
    "    \"\"\"\n",
    "    frame    : the input frame in BGR color space\n",
    "    lower    : the lower bound for skin in HSV space\n",
    "    upper    : the upper bound for skin in HSV space\n",
    "    \"\"\"\n",
    "    # convert the frame from default BGR to HSV color space\n",
    "    frameHSV = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # apply the skin boundary to frame in HSV, get the mask for detected skin area in current frame\n",
    "    skinMask = cv2.inRange(frameHSV, lower, upper)\n",
    "    # apply morphological operation to the mask to remove noise\n",
    "    # define the kernel for morphological operation\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    # (1) use morphological opening to remove small object\n",
    "    skinMask = cv2.erode(skinMask, kernel, iterations = 2)\n",
    "    skinMask = cv2.dilate(skinMask, kernel, iterations = 2)\n",
    "    # (2) use morphological closing to fill small holes in object\n",
    "    skinMask = cv2.erode(skinMask, kernel, iterations = 2)\n",
    "    skinMask = cv2.dilate(skinMask, kernel, iterations = 2)\n",
    "    \n",
    "    return skinMask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Run Program</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VideoProcess():\n",
    "    global KS, CONTINUE\n",
    "    # get the default camera in your system configuration\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    peakHSVs = []\n",
    "    BoundaryDefined = False\n",
    "\n",
    "    ifPressed = [0] * 12\n",
    "\n",
    "    while(True):\n",
    "        # get current frame\n",
    "        ret, frame = cap.read()\n",
    "        # flip the frame horizontally\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        # check if frame is successfully read\n",
    "        if not ret:\n",
    "            break\n",
    "        # show the current frame\n",
    "        cv2.imshow('frame',  frame)\n",
    "\n",
    "        # resize the frame to decrease the computation\n",
    "        # frame = imutils.resize(frame, width = 500)\n",
    "\n",
    "        if len(peakHSVs) < 10:\n",
    "            # get face roi\n",
    "            ret, faceDetected, peakHSV = getDetectedFace(frame)\n",
    "            # display face roi\n",
    "            cv2.imshow('faceDetected',  faceDetected)\n",
    "            # put detected face to list\n",
    "            if ret:\n",
    "                peakHSVs.append(peakHSV)\n",
    "\n",
    "        elif not BoundaryDefined:\n",
    "            meanHSV = np.mean(peakHSVs, axis=0)\n",
    "            meanHSV = meanHSV.astype(\"uint8\")\n",
    "            print(meanHSV)\n",
    "            lower = meanHSV - [10, 50, 50]\n",
    "            upper = meanHSV + [10, 50, 50]\n",
    "            BoundaryDefined = True\n",
    "            print(\"boundary defined\")\n",
    "            meanRGB = cv2.cvtColor(meanHSV, cv2.COLOR_HSV2RGB)\n",
    "            blank_image = np.zeros((100,100,3), np.uint8)\n",
    "            blank_image[:,:] = meanRGB\n",
    "            plt.imshow(blank_image)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        if BoundaryDefined:\n",
    "            # get skin mask\n",
    "            skinMask = getSkinMask(frame, lower, upper)\n",
    "            skinMask[np.where(skinMask==255)] = 1\n",
    "            # apply mask to frame\n",
    "            frame = apply_mask(frame, skinMask, color=[1.0, 0, 0], alpha=0.5)\n",
    "            # display skin mask\n",
    "            cv2.imshow('skinMask',  skinMask)\n",
    "            # plot key board on current frame \n",
    "            w,h,c = frame.shape\n",
    "            for i in range(12):\n",
    "                # get key position\n",
    "                y1 = int(w / 3) * 2\n",
    "                x1 = int(h / 12) * i \n",
    "                kw = int(h / 30)\n",
    "                kh = int(w / 3)\n",
    "                # plot key on current frame\n",
    "                cv2.rectangle(frame,(x1, y1),(x1 + kw , y1 + kh),(0,255,0),2)\n",
    "                # check if pressed:\n",
    "                p = np.sum(skinMask[y1:y1+kh,x1:x1 + kw]) * 1.0 / (kh * kw)\n",
    "                if p > 0.5:\n",
    "                    if ifPressed[i] == 0:\n",
    "                        print(\"key {} triggered\".format(i+1))\n",
    "                        KS[i] = 1\n",
    "                        \"\"\"\n",
    "                        Generate Sound Here For corresponding key (key i + 1)\n",
    "                        \"\"\"\n",
    "                    ifPressed[i] = 1\n",
    "                else:\n",
    "                    ifPressed[i] = 0\n",
    "\n",
    "            cv2.imshow('Resultframe',  frame)\n",
    "\n",
    "        # exit the program when \"q\" key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            CONTINUE = False\n",
    "            break\n",
    "\n",
    "    # release the camera and destroy the window when program is terminated\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Audio Generation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AudioGeneration():\n",
    "    global KS, CONTINUE\n",
    "    \n",
    "    BLOCKLEN   = 64        # Number of frames per block\n",
    "    WIDTH       = 2         # Bytes per sample\n",
    "    CHANNELS    = 1         # Mono\n",
    "    RATE        = 16000    # Frames per second\n",
    "\n",
    "    MAXVALUE = 2**15-1  # Maximum allowed output signal value (because WIDTH = 2)\n",
    "\n",
    "    # Parameters\n",
    "    Ta = 1      # Decay time (seconds)\n",
    "    f0 = 440    # Frequency (Hz)\n",
    "    f = np.zeros(12)\n",
    "    for n in range(12):\n",
    "        f[n] = f0 * (2 ** (n/12))\n",
    "\n",
    "    # Pole radius and angle\n",
    "    r = 0.01**(1.0/(Ta*RATE))       # 0.01 for 1 percent amplitude\n",
    "    om = np.zeros(12)\n",
    "    for n in range(12):\n",
    "        om[n] = 2.0 * pi * float(f[n])/RATE\n",
    "        \n",
    "    \n",
    "    # Filter coefficients (second-order IIR)\n",
    "    a1 = [1, -2*r*cos(om[0]), r**2]\n",
    "    b1 = [r*sin(om[0])]\n",
    "    a2 = [1, -2*r*cos(om[1]), r**2]\n",
    "    b2 = [r*sin(om[1])]\n",
    "    a3 = [1, -2*r*cos(om[2]), r**2]\n",
    "    b3 = [r*sin(om[2])]\n",
    "    a4 = [1, -2*r*cos(om[3]), r**2]\n",
    "    b4 = [r*sin(om[3])]\n",
    "    a5 = [1, -2*r*cos(om[4]), r**2]\n",
    "    b5 = [r*sin(om[4])]\n",
    "    a6 = [1, -2*r*cos(om[5]), r**2]\n",
    "    b6 = [r*sin(om[5])]\n",
    "    a7 = [1, -2*r*cos(om[6]), r**2]\n",
    "    b7 = [r*sin(om[6])]\n",
    "    a8 = [1, -2*r*cos(om[7]), r**2]\n",
    "    b8 = [r*sin(om[7])]\n",
    "    a9 = [1, -2*r*cos(om[8]), r**2]\n",
    "    b9 = [r*sin(om[8])]\n",
    "    a0 = [1, -2*r*cos(om[9]), r**2]\n",
    "    b0 = [r*sin(om[9])]\n",
    "    a_ = [1, -2*r*cos(om[10]), r**2]\n",
    "    b_ = [r*sin(om[10])]\n",
    "    aEQ = [1, -2*r*cos(om[11]), r**2]\n",
    "    bEQ = [r*sin(om[11])]\n",
    "\n",
    "    ORDER = 2   # filter order\n",
    "    states1 = np.zeros(ORDER)\n",
    "    states2 = np.zeros(ORDER)\n",
    "    states3 = np.zeros(ORDER)\n",
    "    states4 = np.zeros(ORDER)\n",
    "    states5 = np.zeros(ORDER)\n",
    "    states6 = np.zeros(ORDER)\n",
    "    states7 = np.zeros(ORDER)\n",
    "    states8 = np.zeros(ORDER)\n",
    "    states9 = np.zeros(ORDER)\n",
    "    states0 = np.zeros(ORDER)\n",
    "    states_ = np.zeros(ORDER)\n",
    "    statesEQ = np.zeros(ORDER)\n",
    "    x1 = np.zeros(BLOCKLEN)     #La\n",
    "    x2 = np.zeros(BLOCKLEN)     #La#\n",
    "    x3 = np.zeros(BLOCKLEN)     #Si\n",
    "    x4 = np.zeros(BLOCKLEN)     #Do\n",
    "    x5 = np.zeros(BLOCKLEN)     #Do#\n",
    "    x6 = np.zeros(BLOCKLEN)     #Re\n",
    "    x7 = np.zeros(BLOCKLEN)     #Re#\n",
    "    x8 = np.zeros(BLOCKLEN)     #Mi\n",
    "    x9 = np.zeros(BLOCKLEN)     #Fa\n",
    "    x0 = np.zeros(BLOCKLEN)     #Fa#\n",
    "    x_ = np.zeros(BLOCKLEN)     #So\n",
    "    xEQ = np.zeros(BLOCKLEN)    #So#\n",
    "\n",
    "    # Open the audio output stream\n",
    "    p = pyaudio.PyAudio()\n",
    "    PA_FORMAT = pyaudio.paInt16\n",
    "    stream = p.open(\n",
    "            format      = PA_FORMAT,\n",
    "            channels    = CHANNELS,\n",
    "            rate        = RATE,\n",
    "            input       = False,\n",
    "            output      = True,\n",
    "            frames_per_buffer = 128)\n",
    "# specify low frames_per_buffer to reduce latency\n",
    "    \n",
    "    while CONTINUE:\n",
    "\n",
    "        if KS[0] and CONTINUE:\n",
    "            x1[0] = 10000.0\n",
    "        if KS[1] and CONTINUE:\n",
    "            x2[0] = 10000.0\n",
    "        if KS[2] and CONTINUE:\n",
    "            x3[0] = 10000.0\n",
    "        if KS[3] and CONTINUE:\n",
    "            x4[0] = 10000.0\n",
    "        if KS[4] and CONTINUE:\n",
    "            x5[0] = 10000.0\n",
    "        if KS[5] and CONTINUE:\n",
    "            x6[0] = 10000.0\n",
    "        if KS[6] and CONTINUE:\n",
    "            x7[0] = 10000.0\n",
    "        if KS[7] and CONTINUE:\n",
    "            x8[0] = 10000.0\n",
    "        if KS[8] and CONTINUE:\n",
    "            x9[0] = 10000.0\n",
    "        if KS[9] and CONTINUE:\n",
    "            x0[0] = 10000.0\n",
    "        if KS[10] and CONTINUE:\n",
    "            x_[0] = 10000.0\n",
    "        if KS[11] and CONTINUE:\n",
    "            xEQ[0] = 10000.0\n",
    "\n",
    "        [y1, states1] = signal.lfilter(b1, a1, x1, zi = states1)\n",
    "        [y2, states2] = signal.lfilter(b2, a2, x2, zi = states2)\n",
    "        [y3, states3] = signal.lfilter(b3, a3, x3, zi = states3)\n",
    "        [y4, states4] = signal.lfilter(b4, a4, x4, zi = states4)\n",
    "        [y5, states5] = signal.lfilter(b5, a5, x5, zi = states5)\n",
    "        [y6, states6] = signal.lfilter(b6, a6, x6, zi = states6)\n",
    "        [y7, states7] = signal.lfilter(b7, a7, x7, zi = states7)\n",
    "        [y8, states8] = signal.lfilter(b8, a8, x8, zi = states8)\n",
    "        [y9, states9] = signal.lfilter(b9, a9, x9, zi = states9)\n",
    "        [y0, states0] = signal.lfilter(b0, a0, x0, zi = states0)\n",
    "        [y_, states_] = signal.lfilter(b_, a_, x_, zi = states_)\n",
    "        [yEQ, statesEQ] = signal.lfilter(bEQ, aEQ, xEQ, zi = statesEQ)\n",
    "\n",
    "        x1[0] = 0.0\n",
    "        x2[0] = 0.0\n",
    "        x3[0] = 0.0\n",
    "        x4[0] = 0.0\n",
    "        x5[0] = 0.0\n",
    "        x6[0] = 0.0\n",
    "        x7[0] = 0.0\n",
    "        x8[0] = 0.0\n",
    "        x9[0] = 0.0\n",
    "        x0[0] = 0.0\n",
    "        x_[0] = 0.0\n",
    "        xEQ[0] = 0.0\n",
    "\n",
    "        KS = [0] * 12\n",
    "\n",
    "        Y = y1+y2+y3+y4+y5+y6+y7+y8+y9+y0+y_+yEQ\n",
    "        Y = Y.astype(int)\n",
    "        Y = np.clip(Y, -MAXVALUE, MAXVALUE)     # Clipping\n",
    "\n",
    "        binary_data = struct.pack('h' * BLOCKLEN, *Y);    # Convert to binary binary data\n",
    "        stream.write(binary_data, BLOCKLEN)               # Write binary binary data to audio output\n",
    "\n",
    "    print('* Done.')\n",
    "\n",
    "    # Close audio stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Run Real-Time Video Process and Real-Time Audio Generation on Two Threads</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Currently, Multi-Threding May Raise Error On Mac, Tested on Windows</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = []\n",
    "\n",
    "t1 = threading.Thread(target=VideoProcess)\n",
    "threads.append(t1)\n",
    "t2 = threading.Thread(target=AudioGeneration)\n",
    "threads.append(t2)\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
