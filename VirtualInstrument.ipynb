{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import imutils\n",
    "import os\n",
    "from os.path import realpath, normpath\n",
    "\n",
    "import binascii\n",
    "import struct\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import scipy.cluster\n",
    "\n",
    "import random\n",
    "import colorsys\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Utility Function</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_colors(N, bright=True):\n",
    "    \"\"\"\n",
    "    Generate random colors.\n",
    "    To get visually distinct colors, generate them in HSV space then\n",
    "    convert to RGB.\n",
    "    \"\"\"\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    random.shuffle(colors)\n",
    "    return colors\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask == 255,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Face Recognition With Haar Feature-Based Cascade Classifiers</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDetectedFace(frame):\n",
    "    \"\"\"\n",
    "    frame    : the input frame in BGR color space\n",
    "    \"\"\"\n",
    "    NUM_CLUSTERS = 5\n",
    "    FaceDetected = False\n",
    "    peakHSV = None\n",
    "    # get xml path \n",
    "    s = realpath(cv2.__file__).split(\"/\")[:-1]\n",
    "    xmlPath = \"/\" + os.path.join(os.path.join(*s), \"data\")\n",
    "    # Load the cascade classifier\n",
    "    face_cascade = cv2.CascadeClassifier(os.path.join(xmlPath, 'haarcascade_frontalface_default.xml'))\n",
    "    eye_cascade = cv2.CascadeClassifier(os.path.join(xmlPath, 'haarcascade_eye.xml'))\n",
    "    # Convert the frame from default BGR to Gray color space\n",
    "    frameGray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Use Histogram Equalization to enhance the contrast\n",
    "    frameGray = cv2.equalizeHist(frameGray)\n",
    "\n",
    "    # detect face in current frame\n",
    "    faces = face_cascade.detectMultiScale(frameGray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = frameGray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    \n",
    "    if len(faces) > 0:\n",
    "        print(\"face detected\")\n",
    "        FaceDetected = True\n",
    "        image = frame[y:y+h, x:x+w]\n",
    "        shape = image.shape\n",
    "        ar = image.reshape(scipy.product(shape[:2]), shape[2]).astype(float)\n",
    "        codes, dist = scipy.cluster.vq.kmeans(ar, NUM_CLUSTERS)\n",
    "        vecs, dist = scipy.cluster.vq.vq(ar, codes)         # assign codes\n",
    "        counts, bins = scipy.histogram(vecs, len(codes))    # count occurrences\n",
    "        index_max = scipy.argmax(counts)                    # find most frequent\n",
    "        peak = codes[index_max]\n",
    "        peak = peak.reshape(1,1,3)\n",
    "        peak = peak.astype(\"uint8\")\n",
    "        peakHSV = cv2.cvtColor(peak, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    return FaceDetected, frame, peakHSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Skin Detection using HSV boundary</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSkinMask(frame, lower, upper):\n",
    "    \"\"\"\n",
    "    frame    : the input frame in BGR color space\n",
    "    lower    : the lower bound for skin in HSV space\n",
    "    upper    : the upper bound for skin in HSV space\n",
    "    \"\"\"\n",
    "    # convert the frame from default BGR to HSV color space\n",
    "    frameHSV = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # apply the skin boundary to frame in HSV, get the mask for detected skin area in current frame\n",
    "    skinMask = cv2.inRange(frameHSV, lower, upper)\n",
    "    # apply morphological operation to the mask to remove noise\n",
    "    # define the kernel for morphological operation\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    # (1) use morphological opening to remove small object\n",
    "    skinMask = cv2.erode(skinMask, kernel, iterations = 2)\n",
    "    skinMask = cv2.dilate(skinMask, kernel, iterations = 2)\n",
    "    # (2) use morphological closing to fill small holes in object\n",
    "    skinMask = cv2.erode(skinMask, kernel, iterations = 2)\n",
    "    skinMask = cv2.dilate(skinMask, kernel, iterations = 2)\n",
    "    \n",
    "    return skinMask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Run Program</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the lower bound and upper bound for skin detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the upper and lower boundaries of skin color in HSV color space\n",
    "lower = np.array([0, 48, 80], dtype = \"uint8\")\n",
    "upper = np.array([20, 255, 255], dtype = \"uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face detected\n",
      "face detected\n",
      "face detected\n",
      "face detected\n",
      "face detected\n",
      "face detected\n",
      "face detected\n",
      "face detected\n",
      "face detected\n",
      "face detected\n",
      "[[[  6  88 120]]]\n",
      "boundary defined\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhgxfasjwpYYMX2rI8KWG/gdcgaKoOREr8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the default camera in your system configuration\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "peakHSVs = []\n",
    "BoundaryDefined = False\n",
    "\n",
    "while(True):\n",
    "    # get current frame\n",
    "    ret, frame = cap.read()\n",
    "    # flip the frame horizontally\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    # check if frame is successfully read\n",
    "    if not ret:\n",
    "        break\n",
    "    # show the current frame\n",
    "    cv2.imshow('frame',  frame)\n",
    "    \n",
    "    # resize the frame to decrease the computation\n",
    "    frame = imutils.resize(frame, width = 500)\n",
    "    \n",
    "    if len(peakHSVs) < 10:\n",
    "        # get face roi\n",
    "        ret, faceDetected, peakHSV = getDetectedFace(frame)\n",
    "        # display face roi\n",
    "        cv2.imshow('faceDetected',  faceDetected)\n",
    "        # put detected face to list\n",
    "        if ret:\n",
    "            peakHSVs.append(peakHSV)\n",
    "            \n",
    "    elif not BoundaryDefined:\n",
    "        meanHSV = np.mean(peakHSVs, axis=0)\n",
    "        meanHSV = meanHSV.astype(\"uint8\")\n",
    "        print(meanHSV)\n",
    "        lower = meanHSV - [10, 50, 50]\n",
    "        upper = meanHSV + [10, 50, 50]\n",
    "        BoundaryDefined = True\n",
    "        print(\"boundary defined\")\n",
    "        meanRGB = cv2.cvtColor(meanHSV, cv2.COLOR_HSV2RGB)\n",
    "        blank_image = np.zeros((100,100,3), np.uint8)\n",
    "        blank_image[:,:] = meanRGB\n",
    "        plt.imshow(blank_image)\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    if BoundaryDefined:\n",
    "        # get skin mask\n",
    "        skinMask = getSkinMask(frame, lower, upper)\n",
    "        # apply mask to frame\n",
    "        frame = apply_mask(frame, skinMask, color=[1.0, 0, 0], alpha=0.5)\n",
    "        # display skin mask\n",
    "        cv2.imshow('skinMask',  skinMask)\n",
    "        # plot key board on current frame \n",
    "        w,h,c = frame.shape\n",
    "        for i in range(6):\n",
    "            y1 = int(w / 3) * 2\n",
    "            x1 = int(h / 6) * i \n",
    "            kw = int(h / 20)\n",
    "            kh = int(w / 3)\n",
    "            cv2.rectangle(frame,(x1, y1),(x1 + kw , y1 + kh),(0,255,0),2)\n",
    "        cv2.imshow('Resultframe',  frame)\n",
    "        \n",
    "    \n",
    "    \n",
    "    # exit the program when \"q\" key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release the camera and destroy the window when program is terminated\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    # get current frame\n",
    "    ret, frame = cap.read()\n",
    "    # flip the frame horizontally\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    # check if frame is successfully read\n",
    "    if not ret:\n",
    "        break\n",
    "    # show the current frame\n",
    "    cv2.imshow('frame',  frame)\n",
    "    \n",
    "    frame = imutils.resize(frame, width = 500)\n",
    "    \n",
    "    w,h,c = frame.shape\n",
    "    \n",
    "    #for keycnt in keycnts:\n",
    "    for i in range(6):\n",
    "        y1 = int(w / 3) * 2\n",
    "        x1 = int(h / 6) * i \n",
    "        kw = int(h / 20)\n",
    "        kh = int(w / 3)\n",
    "    #    (xg,yg,wg,hg) = cv2.boundingRect(keycnt)\n",
    "        cv2.rectangle(frame,(x1, y1),(x1 + kw , y1 + kh),(0,255,0),2)\n",
    "    \n",
    "    cv2.imshow('frameKey',  frame)\n",
    "    \n",
    "    # exit the program when \"q\" key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release the camera and destroy the window when program is terminated\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281, 500, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,h,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.66666666666667"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(w / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  42, 150], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LightPinkHSV[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(skinMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
