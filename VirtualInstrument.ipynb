{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import imutils\n",
    "import os\n",
    "from os.path import realpath, normpath\n",
    "\n",
    "import binascii\n",
    "import struct\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import scipy.cluster\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Face Recognition With Haar Feature-Based Cascade Classifiers</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDetectedFace(frame):\n",
    "    \"\"\"\n",
    "    frame    : the input frame in BGR color space\n",
    "    \"\"\"\n",
    "    NUM_CLUSTERS = 5\n",
    "    FaceDetected = False\n",
    "    peakHSV = None\n",
    "    # get xml path \n",
    "    s = realpath(cv2.__file__).split(\"/\")[:-1]\n",
    "    xmlPath = \"/\" + os.path.join(os.path.join(*s), \"data\")\n",
    "    # Load the cascade classifier\n",
    "    face_cascade = cv2.CascadeClassifier(os.path.join(xmlPath, 'haarcascade_frontalface_default.xml'))\n",
    "    eye_cascade = cv2.CascadeClassifier(os.path.join(xmlPath, 'haarcascade_eye.xml'))\n",
    "    # Convert the frame from default BGR to Gray color space\n",
    "    frameGray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Use Histogram Equalization to enhance the contrast\n",
    "    frameGray = cv2.equalizeHist(frameGray)\n",
    "\n",
    "    # detect face in current frame\n",
    "    faces = face_cascade.detectMultiScale(frameGray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = frameGray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    \n",
    "    if len(faces) > 0:\n",
    "        FaceDetected = True\n",
    "        image = frame[y:y+h, x:x+w]\n",
    "        shape = image.shape\n",
    "        print(shape)\n",
    "        ar = image.reshape(scipy.product(shape[:2]), shape[2]).astype(float)\n",
    "        codes, dist = scipy.cluster.vq.kmeans(ar, NUM_CLUSTERS)\n",
    "        vecs, dist = scipy.cluster.vq.vq(ar, codes)         # assign codes\n",
    "        counts, bins = scipy.histogram(vecs, len(codes))    # count occurrences\n",
    "        index_max = scipy.argmax(counts)                    # find most frequent\n",
    "        peak = codes[index_max]\n",
    "        peak = peak.reshape(1,1,3)\n",
    "        peak = peak.astype(\"uint8\")\n",
    "        peakHSV = cv2.cvtColor(peak, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    return FaceDetected, frame, peakHSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Skin Detection using HSV boundary</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSkinMask(frame, lower, upper):\n",
    "    \"\"\"\n",
    "    frame    : the input frame in BGR color space\n",
    "    lower    : the lower bound for skin in HSV space\n",
    "    upper    : the upper bound for skin in HSV space\n",
    "    \"\"\"\n",
    "    # convert the frame from default BGR to HSV color space\n",
    "    frameHSV = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # apply the skin boundary to frame in HSV, get the mask for detected skin area in current frame\n",
    "    skinMask = cv2.inRange(frameHSV, lower, upper)\n",
    "    # apply morphological operation to the mask to remove noise\n",
    "    # define the kernel for morphological operation\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    # (1) use morphological opening to remove small object\n",
    "    skinMask = cv2.erode(skinMask, kernel, iterations = 2)\n",
    "    skinMask = cv2.dilate(skinMask, kernel, iterations = 2)\n",
    "    # (2) use morphological closing to fill small holes in object\n",
    "    skinMask = cv2.erode(skinMask, kernel, iterations = 2)\n",
    "    skinMask = cv2.dilate(skinMask, kernel, iterations = 2)\n",
    "    \n",
    "    return skinMask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Run Program</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the lower bound and upper bound for skin detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the upper and lower boundaries of skin color in HSV color space\n",
    "lower = np.array([0, 48, 80], dtype = \"uint8\")\n",
    "upper = np.array([20, 255, 255], dtype = \"uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174, 174, 3)\n",
      "(188, 188, 3)\n",
      "(170, 170, 3)\n",
      "(170, 170, 3)\n",
      "(174, 174, 3)\n",
      "(185, 185, 3)\n",
      "(171, 171, 3)\n",
      "(180, 180, 3)\n",
      "(176, 176, 3)\n",
      "(178, 178, 3)\n",
      "boundary defined\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDF9qyPClhgxfauh/AOFwoqppn8P7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the default camera in your system configuration\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "peakHSVs = []\n",
    "BoundaryDefined = False\n",
    "while(True):\n",
    "    # get current frame\n",
    "    ret, frame = cap.read()\n",
    "    # check if frame is successfully read\n",
    "    if not ret:\n",
    "        break\n",
    "    # show the current frame\n",
    "    cv2.imshow('frame',  frame)\n",
    "    \n",
    "    # resize the frame to decrease the computation\n",
    "    frame = imutils.resize(frame, width = 500)\n",
    "    \n",
    "    if len(peakHSVs) < 10:\n",
    "        # get face roi\n",
    "        ret, faceDetected, peakHSV = getDetectedFace(frame)\n",
    "        # display face roi\n",
    "        cv2.imshow('faceDetected',  faceDetected)\n",
    "        # put detected face to list\n",
    "        if ret:\n",
    "            peakHSVs.append(peakHSV)\n",
    "            \n",
    "    elif not BoundaryDefined:\n",
    "        meanHSV = np.mean(peakHSVs, axis=0)\n",
    "        meanHSV = meanHSV.astype(\"uint8\")\n",
    "        lower = meanHSV - [20, 80, 80]\n",
    "        upper = meanHSV + [20, 80, 80]\n",
    "        BoundaryDefined = True\n",
    "        print(\"boundary defined\")\n",
    "        meanRGB = cv2.cvtColor(meanHSV, cv2.COLOR_HSV2RGB)\n",
    "        blank_image = np.zeros((100,100,3), np.uint8)\n",
    "        blank_image[:,:] = meanRGB\n",
    "        plt.imshow(blank_image)\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    if BoundaryDefined:\n",
    "        skinMask = getSkinMask(frame, lower, upper)\n",
    "        # display skin mask\n",
    "        cv2.imshow('skinMask',  skinMask)\n",
    "    \n",
    "    \n",
    "    # exit the program when \"q\" key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release the camera and destroy the window when program is terminated\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
